#!/usr/bin/env python3
"""
üé≠ Aniemore SER Service
HTTP —Å–µ—Ä–≤–∏—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π –≤ –≥–æ–ª–æ—Å–µ —Å –ø–æ–º–æ—â—å—é Aniemore/wavlm-emotion-russian-resd
"""

import asyncio
import logging
import tempfile
import os
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import json
import time
import base64
import aiohttp

import uvicorn
from contextlib import asynccontextmanager
from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import librosa
import numpy as np
import torch
from transformers import AutoModelForAudioClassification, AutoFeatureExtractor, AutoTokenizer, AutoModelForSequenceClassification
from aniemore.recognizers.voice import VoiceRecognizer
from aniemore.recognizers.text import TextRecognizer
from aniemore.models import HuggingFaceModel

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Manage application lifespan"""
    # Startup
    logger.info("[INFO] –ó–∞–ø—É—Å–∫ Aniemore SER Service...")
    
    # –ü–æ–ø—ã—Ç–∫–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    max_retries = 3
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            logger.info(f"[INFO] –ü–æ–ø—ã—Ç–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ {attempt + 1}/{max_retries}")
            await ser_service.initialize()
            logger.info("[INFO] Aniemore SER Service –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
            break
        except Exception as e:
            logger.error(f"[ERROR] –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                logger.info(f"[INFO] –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {retry_delay} —Å–µ–∫—É–Ω–¥...")
                await asyncio.sleep(retry_delay)
                retry_delay *= 2  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
            else:
                logger.warning("[WARNING] –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–µ—Ä–≤–∏—Å –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ")
                logger.info("[INFO] Aniemore SER Service –∑–∞–ø—É—â–µ–Ω (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–ª–æ–∂–µ–Ω–∞ –¥–æ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞)")
    
    yield
    # Shutdown
    logger.info("[INFO] Aniemore SER Service –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É...")
    if hasattr(app.state, 'voice_recognizer') and app.state.voice_recognizer:
        logger.info("[INFO] –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ Aniemore...")
        # –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ Aniemore (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    logger.info("[INFO] Aniemore SER Service –∑–∞–≤–µ—Ä—à–µ–Ω")

app = FastAPI(
    title="Aniemore SER Service",
    description="""
    –°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π –≤ –≥–æ–ª–æ—Å–µ –∏ —Ç–µ–∫—Å—Ç–µ —Å –ø–æ–º–æ—â—å—é Aniemore.
    
    **–í–∞–∂–Ω–æ**: WavLM - —ç—Ç–æ –∞—É–¥–∏–æ-—Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π –≤ –≥–æ–ª–æ—Å–µ.
    –¢–µ–∫—Å—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ Aniemore Text –∏ Dostoevsky –º–æ–¥–µ–ª–∏.
    –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    """,
    version="1.0.0",
    lifespan=lifespan
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    """Root endpoint"""
    try:
        logger.info("[ROOT] –ó–∞–ø—Ä–æ—Å –∫ –∫–æ—Ä–Ω–µ–≤–æ–º—É endpoint")
        return {
            "service": "Aniemore SER Service",
            "version": "1.0.0",
            "status": "running",
            "endpoints": [
                "/health",
                "/model-info",
                "/analyze-bytes",
                "/analyze-bytes-json",
                "/analyze-text"
            ]
        }
    except Exception as e:
        logger.error(f"[ROOT] –û—à–∏–±–∫–∞: {e}")
        import traceback
        logger.error(f"[ROOT] Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

class AniemoreSERService:
    def __init__(self):
        self.voice_recognizer = None
        self.text_recognizer = None
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU –∏–∑-–∑–∞ CUDA –æ—à–∏–±–æ–∫
        self.device = "cpu"
        self.is_initialized = False
        self.text_initialized = False
        
        # –ü—É—Ç–∏ –∫ –ª–æ–∫–∞–ª—å–Ω—ã–º –º–æ–¥–µ–ª—è–º
        self.models_dir = Path(__file__).parent.parent / "models"
        self.voice_model_path = self.models_dir / "aniemore" / "voice"
        self.text_model_path = self.models_dir / "aniemore" / "text"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        self.use_local_models = self.voice_model_path.exists() and self.text_model_path.exists()
        
        if self.use_local_models:
            logger.info(f"[INFO] –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ Aniemore:")
            logger.info(f"[INFO] Voice: {self.voice_model_path}")
            logger.info(f"[INFO] Text: {self.text_model_path}")
            self.voice_model = str(self.voice_model_path)
            self.text_model = str(self.text_model_path)
            self.model_name = "Aniemore/wavlm-emotion-russian-resd (local)"
            self.text_model_name = "Aniemore/rubert-tiny2-russian-emotion-detection (local)"
        else:
            logger.info(f"[INFO] –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º HuggingFace:")
            logger.info(f"[INFO] Voice: {self.voice_model_path} - {self.voice_model_path.exists()}")
            logger.info(f"[INFO] Text: {self.text_model_path} - {self.text_model_path.exists()}")
            self.voice_model = HuggingFaceModel.Voice.WavLM
            self.text_model = HuggingFaceModel.Text.Bert_Tiny2
            self.model_name = "Aniemore/wavlm-emotion-russian-resd"
            self.text_model_name = "Aniemore/rubert-tiny2-russian-emotion-detection"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        self.model = None  # –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        
        # –ú–∞–ø–ø–∏–Ω–≥ —ç–º–æ—Ü–∏–π –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
        self.emotion_mapping = {
            "angry": "–∑–ª–æ—Å—Ç—å",
            "anger": "–∑–ª–æ—Å—Ç—å",
            "calm": "—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ", 
            "disgust": "–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ",
            "fearful": "—Å—Ç—Ä–∞—Ö",
            "fear": "—Å—Ç—Ä–∞—Ö",
            "happy": "—Ä–∞–¥–æ—Å—Ç—å",
            "happiness": "—Ä–∞–¥–æ—Å—Ç—å",
            "enthusiasm": "—ç–Ω—Ç—É–∑–∏–∞–∑–º",
            "neutral": "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è",
            "sad": "–≥—Ä—É—Å—Ç—å",
            "sadness": "–≥—Ä—É—Å—Ç—å",
            "surprised": "—É–¥–∏–≤–ª–µ–Ω–∏–µ"
        }
        
        # URL –¥—Ä—É–≥–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
        self.whispercpp_url = "http://localhost:8002/transcribe"
        self.dostoevsky_url = "http://localhost:8007/analyze"
        
        # –¢–∞–π–º–∞—É—Ç—ã –¥–ª—è HTTP –∑–∞–ø—Ä–æ—Å–æ–≤
        self.timeouts = {
            "whispercpp": 30,
            "dostoevsky": 30
        }
        
        # –í–µ—Å–∞ —É–±—Ä–∞–Ω—ã - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —ç–º–æ—Ü–∏–π —Ç–µ–ø–µ—Ä—å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ Rust
    
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ Aniemore SER"""
        if self.is_initialized:
            return
        
        logger.info(f"[INFO] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Aniemore Voice Recognizer: {self.voice_model}")
        
        try:
            if self.use_local_models:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ transformers
                logger.info(f"[INFO] –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –≥–æ–ª–æ—Å–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏–∑: {self.voice_model}")
                from transformers import AutoModelForAudioClassification, AutoFeatureExtractor
                
                # –ù–∞—Ö–æ–¥–∏–º snapshot –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                snapshots_dir = Path(self.voice_model) / "snapshots"
                if snapshots_dir.exists():
                    snapshot_dirs = list(snapshots_dir.iterdir())
                    if snapshot_dirs:
                        model_path = snapshot_dirs[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π snapshot
                        logger.info(f"[INFO] –ò—Å–ø–æ–ª—å–∑—É–µ–º snapshot: {model_path}")
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ feature extractor
                        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º float32 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å CUDA
                        self.model = AutoModelForAudioClassification.from_pretrained(
                            str(model_path), 
                            torch_dtype=torch.float32  # –í—Å–µ–≥–¥–∞ float32 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                        ).to(self.device)
                        
                        self.feature_extractor = AutoFeatureExtractor.from_pretrained(str(model_path))
                        
                        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π VoiceRecognizer –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                        class LocalVoiceRecognizer:
                            def __init__(self, model, feature_extractor, device):
                                self.model = model
                                self.feature_extractor = feature_extractor
                                self.device = device
                            
                            def recognize(self, audio_path, return_single_label=True):
                                """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –≤ –∞—É–¥–∏–æ —Ñ–∞–π–ª–µ"""
                                import librosa
                                import torch
                                
                                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
                                audio, sr = librosa.load(audio_path, sr=16000)
                                
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º features
                                inputs = self.feature_extractor(
                                    audio, 
                                    sampling_rate=16000, 
                                    return_tensors="pt"
                                )
                                
                                # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Ç–∏–ø—É –º–æ–¥–µ–ª–∏
                                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                                
                                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º float32 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                                logger.info(f"–¢–∏–ø –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {inputs['input_values'].dtype}")
                                logger.info(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å —Ç–∏–ø–æ–º: {next(self.model.parameters()).dtype}")
                                
                                # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ float32
                                if inputs['input_values'].dtype != torch.float32:
                                    inputs = {k: v.float() for k, v in inputs.items()}
                                    logger.info(f"–ü—Ä–∏–≤–µ–¥–µ–Ω—ã –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫ float32: {inputs['input_values'].dtype}")
                                
                                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                                with torch.no_grad():
                                    outputs = self.model(**inputs)
                                    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
                                    
                                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 —ç–º–æ—Ü–∏–∏
                                top3_indices = torch.topk(predictions[0], k=3).indices
                                top3_confidences = torch.topk(predictions[0], k=3).values
                                
                                # –û—Å–Ω–æ–≤–Ω–∞—è —ç–º–æ—Ü–∏—è (—Ç–æ–ø-1)
                                predicted_class_id = top3_indices[0].item()
                                confidence = top3_confidences[0].item()
                                
                                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π —ç–º–æ—Ü–∏–∏
                                if hasattr(self.model.config, 'id2label'):
                                    emotion = self.model.config.id2label[predicted_class_id]
                                else:
                                    emotion = f"emotion_{predicted_class_id}"
                                
                                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 —ç–º–æ—Ü–∏–∏ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                                top3_emotions = []
                                for i in range(3):
                                    class_id = top3_indices[i].item()
                                    conf = top3_confidences[i].item()
                                    if hasattr(self.model.config, 'id2label'):
                                        emotion_name = self.model.config.id2label[class_id]
                                    else:
                                        emotion_name = f"emotion_{class_id}"
                                    top3_emotions.append({
                                        'emotion': emotion_name,
                                        'confidence': conf,
                                        'class_id': class_id
                                    })
                                
                                logger.info(f"–¢–æ–ø-3 —ç–º–æ—Ü–∏–∏ (–≥–æ–ª–æ—Å): {top3_emotions}")
                                
                                if return_single_label:
                                    return emotion
                                else:
                                    return {
                                        'label': emotion,
                                        'score': confidence,
                                        'top3_emotions': top3_emotions
                                    }
                        
                        self.voice_recognizer = LocalVoiceRecognizer(self.model, self.feature_extractor, self.device)
                    else:
                        raise Exception("–ù–µ –Ω–∞–π–¥–µ–Ω—ã snapshot –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏")
                else:
                    raise Exception("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è snapshots –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏")
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º HuggingFace –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Aniemore API
                logger.info("[INFO] –ó–∞–≥—Ä—É–∑–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ HuggingFace —á–µ—Ä–µ–∑ Aniemore...")
                self.voice_recognizer = VoiceRecognizer(model=self.voice_model, device=self.device)
                self.model = self.voice_recognizer.model
            
            logger.info(f"[OK] –ì–æ–ª–æ—Å–æ–≤–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {self.device}")
            self.is_initialized = True
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å
            logger.info("[INFO] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ Aniemore...")
            await self.initialize_text_model()
            
        except Exception as e:
            logger.error(f"[ERROR] –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
    
    async def initialize_text_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ Aniemore"""
        if self.text_initialized:
            return
        
        logger.info(f"[INFO] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {self.text_model}")
        
        try:
            if self.use_local_models:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ transformers
                logger.info(f"[INFO] –ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏–∑: {self.text_model}")
                from transformers import AutoModelForSequenceClassification, AutoTokenizer
                
                # –ù–∞—Ö–æ–¥–∏–º snapshot –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                snapshots_dir = Path(self.text_model) / "snapshots"
                if snapshots_dir.exists():
                    snapshot_dirs = list(snapshots_dir.iterdir())
                    if snapshot_dirs:
                        model_path = snapshot_dirs[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π snapshot
                        logger.info(f"[INFO] –ò—Å–ø–æ–ª—å–∑—É–µ–º snapshot: {model_path}")
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
                        self.text_model_obj = AutoModelForSequenceClassification.from_pretrained(
                            str(model_path), 
                            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
                        ).to(self.device)
                        
                        self.text_tokenizer = AutoTokenizer.from_pretrained(str(model_path))
                        
                        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π TextRecognizer –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                        class LocalTextRecognizer:
                            def __init__(self, model, tokenizer, device):
                                self.model = model
                                self.tokenizer = tokenizer
                                self.device = device
                            
                            def recognize(self, text, return_single_label=True):
                                """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –≤ —Ç–µ–∫—Å—Ç–µ"""
                                import torch
                                
                                # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
                                inputs = self.tokenizer(
                                    text, 
                                    return_tensors="pt", 
                                    truncation=True, 
                                    padding=True, 
                                    max_length=512
                                )
                                
                                # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                                
                                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                                with torch.no_grad():
                                    outputs = self.model(**inputs)
                                    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
                                    
                                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 —ç–º–æ—Ü–∏–∏
                                top3_indices = torch.topk(predictions[0], k=3).indices
                                top3_confidences = torch.topk(predictions[0], k=3).values
                                
                                # –û—Å–Ω–æ–≤–Ω–∞—è —ç–º–æ—Ü–∏—è (—Ç–æ–ø-1)
                                predicted_class_id = top3_indices[0].item()
                                confidence = top3_confidences[0].item()
                                
                                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π —ç–º–æ—Ü–∏–∏
                                if hasattr(self.model.config, 'id2label'):
                                    emotion = self.model.config.id2label[predicted_class_id]
                                else:
                                    emotion = f"emotion_{predicted_class_id}"
                                
                                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 —ç–º–æ—Ü–∏–∏ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                                top3_emotions = []
                                for i in range(3):
                                    class_id = top3_indices[i].item()
                                    conf = top3_confidences[i].item()
                                    if hasattr(self.model.config, 'id2label'):
                                        emotion_name = self.model.config.id2label[class_id]
                                    else:
                                        emotion_name = f"emotion_{class_id}"
                                    top3_emotions.append({
                                        'emotion': emotion_name,
                                        'confidence': conf,
                                        'class_id': class_id
                                    })
                                
                                logger.info(f"–¢–æ–ø-3 —ç–º–æ—Ü–∏–∏ (—Ç–µ–∫—Å—Ç): {top3_emotions}")
                                
                                if return_single_label:
                                    return emotion
                                else:
                                    return {
                                        'label': emotion,
                                        'score': confidence,
                                        'top3_emotions': top3_emotions
                                    }
                        
                        self.text_recognizer = LocalTextRecognizer(self.text_model_obj, self.text_tokenizer, self.device)
                    else:
                        raise Exception("–ù–µ –Ω–∞–π–¥–µ–Ω—ã snapshot –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
                else:
                    raise Exception("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è snapshots –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º HuggingFace –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Aniemore API
                logger.info("[INFO] –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ HuggingFace —á–µ—Ä–µ–∑ Aniemore...")
                self.text_recognizer = TextRecognizer(model=self.text_model, device=self.device)
            
            logger.info(f"[OK] –¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {self.device}")
            self.text_initialized = True
            
        except Exception as e:
            logger.error(f"[ERROR] –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
    
    async def analyze_emotions(self, audio_data: bytes, sample_rate: int = 16000) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –≤ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö"""
        if not self.is_initialized:
            await self.initialize()
        
        start_time = time.time()
        
        try:
            logger.info(f"üéµ –í—Ö–æ–¥—è—â–∏–µ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ: {len(audio_data)} bytes, sample_rate: {sample_rate} Hz")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª–∏–Ω—ã –∞—É–¥–∏–æ
            if len(audio_data) < 1600:  # < 0.1 —Å–µ–∫ –ø—Ä–∏ 16kHz
                raise HTTPException(status_code=400, detail="–ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ (–º–∏–Ω–∏–º—É–º 0.1 —Å–µ–∫—É–Ω–¥—ã)")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∞—É–¥–∏–æ
            temp_path = None
            try:
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                    temp_file.write(audio_data)
                    temp_file.flush()  # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∞–Ω—ã
                    temp_path = temp_file.name
                
                logger.info(f"üìÅ –°–æ–∑–¥–∞–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {temp_path}")
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
                try:
                    import librosa
                    audio, sr = librosa.load(temp_path, sr=None)
                    if len(audio) < 1600:  # < 0.1 —Å–µ–∫
                        raise HTTPException(status_code=400, detail="–ê—É–¥–∏–æ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏")
                    logger.info(f"üéµ –ê—É–¥–∏–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(audio)} samples, {sr} Hz")
                except Exception as e:
                    raise HTTPException(status_code=400, detail=f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª: {str(e)}")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º Aniemore VoiceRecognizer –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π
                logger.info("üé≠ –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π —Å –ø–æ–º–æ—â—å—é Aniemore...")
                result = self.voice_recognizer.recognize(temp_path, return_single_label=True)
                
                logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç Aniemore: {result}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if isinstance(result, dict):
                    emotion = result.get('label', 'neutral')
                    confidence = result.get('score', 0.0)
                else:
                    # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ —Å —ç–º–æ—Ü–∏–µ–π
                    # –ù—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å confidence –∏–∑ –º–æ–¥–µ–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
                    emotion = str(result)
                    
                    # –ü–æ–ª—É—á–∞–µ–º confidence –∏–∑ –º–æ–¥–µ–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
                    try:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º voice_recognizer –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                        full_result = self.voice_recognizer.recognize(temp_path, return_single_label=False)
                        if isinstance(full_result, dict):
                            confidence = full_result.get('score', 0.5)
                            logger.debug(f"–ü–æ–ª—É—á–µ–Ω confidence –¥–ª—è –≥–æ–ª–æ—Å–∞ –∏–∑ full_result: {confidence}")
                        else:
                            # –ï—Å–ª–∏ full_result –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å confidence –∏–∑ –º–æ–¥–µ–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
                            logger.warning(f"full_result –¥–ª—è –≥–æ–ª–æ—Å–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º: {type(full_result)}, –∑–Ω–∞—á–µ–Ω–∏–µ: {full_result}")
                            # –ü–æ–ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–µ–Ω–∏—è confidence
                            try:
                                # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –≤—ã–∑–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
                                detailed_result = self.voice_recognizer.recognize(temp_path, return_single_label=False)
                                logger.debug(f"–î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –≥–æ–ª–æ—Å–∞: {detailed_result}")
                                if isinstance(detailed_result, dict) and 'score' in detailed_result:
                                    confidence = detailed_result['score']
                                    logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω confidence –¥–ª—è –≥–æ–ª–æ—Å–∞ –∏–∑ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {confidence}")
                                else:
                                    # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ –∑–∞–≥–ª—É—à–∫–∏
                                    confidence = 0.1  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ –∑–∞–≥–ª—É—à–∫–∏ 0.5
                                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å confidence –¥–ª—è –≥–æ–ª–æ—Å–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {confidence}")
                            except Exception as inner_e:
                                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –≥–æ–ª–æ—Å–∞: {inner_e}")
                                confidence = 0.1  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ –∑–∞–≥–ª—É—à–∫–∏ 0.5
                                logger.warning(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ confidence –¥–ª—è –≥–æ–ª–æ—Å–∞: {confidence}")
                    except Exception as e:
                        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ confidence –¥–ª—è –≥–æ–ª–æ—Å–∞: {e}")
                        # –í–º–µ—Å—Ç–æ –∑–∞–≥–ª—É—à–∫–∏ 0.5 –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                        confidence = 0.1
                        logger.warning(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ confidence –¥–ª—è –≥–æ–ª–æ—Å–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {confidence}")
                
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º —ç–º–æ—Ü–∏—é –Ω–∞ —Ä—É—Å—Å–∫–∏–π
                russian_emotion = self.emotion_mapping.get(emotion.lower(), emotion)
                
                processing_time = time.time() - start_time
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 —ç–º–æ—Ü–∏–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ recognize
                top3_emotions = []
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —Ç–æ–ø-3 —ç–º–æ—Ü–∏—è–º–∏
                    full_result_with_top3 = self.voice_recognizer.recognize(temp_path, return_single_label=False)
                    if isinstance(full_result_with_top3, dict) and 'top3_emotions' in full_result_with_top3:
                        top3_emotions = full_result_with_top3['top3_emotions']
                        # –ü–µ—Ä–µ–≤–æ–¥–∏–º —ç–º–æ—Ü–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π
                        for emotion_data in top3_emotions:
                            emotion_data['emotion'] = self.emotion_mapping.get(emotion_data['emotion'].lower(), emotion_data['emotion'])
                        logger.info(f"–ü–æ–ª—É—á–µ–Ω—ã —Ç–æ–ø-3 —ç–º–æ—Ü–∏–∏: {top3_emotions}")
                    else:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–ø-3 —ç–º–æ—Ü–∏–∏ –∏–∑ full_result_with_top3: {full_result_with_top3}")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–æ–ø-3 —ç–º–æ—Ü–∏–π: {e}")
                    top3_emotions = []
                
                result = {
                    "emotion": russian_emotion,
                    "confidence": float(confidence),
                    "processing_time": processing_time,
                    "model": "Aniemore/WavLM",
                    "device": self.device,
                    "top3_emotions": top3_emotions
                }
                
                logger.info(f"[RAW-VOICE] –°—ã—Ä–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {result}")
                return result
                
            finally:
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                if temp_path and os.path.exists(temp_path):
                    try:
                        os.unlink(temp_path)
                        logger.info(f"üóëÔ∏è –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω: {temp_path}")
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {temp_path}: {e}")
        
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π: {e}")
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π: {e}")
    
    async def analyze_text_emotions(self, text: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –≤ —Ç–µ–∫—Å—Ç–µ"""
        if not self.text_initialized:
            await self.initialize_text_model()
        
        start_time = time.time()
        
        try:
            logger.info(f"üìù –í—Ö–æ–¥—è—â–∏–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: '{text}'")
            logger.info(f"üìè –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Aniemore TextRecognizer –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π
            logger.info("üìù –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π —Å –ø–æ–º–æ—â—å—é Aniemore TextRecognizer...")
            result = self.text_recognizer.recognize(text, return_single_label=True)
            
            logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç Aniemore Text: {result}")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if isinstance(result, dict):
                emotion = result.get('label', 'neutral')
                confidence = result.get('score', 0.0)
            else:
                # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ —Å —ç–º–æ—Ü–∏–µ–π
                # –ù—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å confidence –∏–∑ –º–æ–¥–µ–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
                emotion = str(result)
                
                # –ü–æ–ª—É—á–∞–µ–º confidence –∏–∑ –º–æ–¥–µ–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º text_recognizer –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    full_result = self.text_recognizer.recognize(text, return_single_label=False)
                    if isinstance(full_result, dict):
                        confidence = full_result.get('score', 0.5)
                        logger.debug(f"–ü–æ–ª—É—á–µ–Ω confidence –∏–∑ full_result: {confidence}")
                    else:
                        # –ï—Å–ª–∏ full_result –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å confidence –∏–∑ –º–æ–¥–µ–ª–∏ –Ω–∞–ø—Ä—è–º—É—é
                        logger.warning(f"full_result –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º: {type(full_result)}, –∑–Ω–∞—á–µ–Ω–∏–µ: {full_result}")
                        # –ü–æ–ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–µ–Ω–∏—è confidence
                        try:
                            # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –≤—ã–∑–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
                            detailed_result = self.text_recognizer.recognize(text, return_single_label=False)
                            logger.debug(f"–î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {detailed_result}")
                            if isinstance(detailed_result, dict) and 'score' in detailed_result:
                                confidence = detailed_result['score']
                                logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω confidence –∏–∑ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {confidence}")
                            else:
                                # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ –∑–∞–≥–ª—É—à–∫–∏
                                confidence = 0.1  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ –∑–∞–≥–ª—É—à–∫–∏ 0.5
                                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å confidence, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {confidence}")
                        except Exception as inner_e:
                            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {inner_e}")
                            confidence = 0.1  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ –∑–∞–≥–ª—É—à–∫–∏ 0.5
                            logger.warning(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ confidence: {confidence}")
                except Exception as e:
                    logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ confidence: {e}")
                    # –í–º–µ—Å—Ç–æ –∑–∞–≥–ª—É—à–∫–∏ 0.5 –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    confidence = 0.1
                    logger.warning(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ confidence –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {confidence}")
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º —ç–º–æ—Ü–∏—é –Ω–∞ —Ä—É—Å—Å–∫–∏–π
            russian_emotion = self.emotion_mapping.get(emotion.lower(), emotion)
            
            processing_time = time.time() - start_time
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 —ç–º–æ—Ü–∏–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ recognize
            top3_emotions = []
            try:
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —Ç–æ–ø-3 —ç–º–æ—Ü–∏—è–º–∏
                full_result_with_top3 = self.text_recognizer.recognize(text, return_single_label=False)
                if isinstance(full_result_with_top3, dict) and 'top3_emotions' in full_result_with_top3:
                    top3_emotions = full_result_with_top3['top3_emotions']
                    # –ü–µ—Ä–µ–≤–æ–¥–∏–º —ç–º–æ—Ü–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π
                    for emotion_data in top3_emotions:
                        emotion_data['emotion'] = self.emotion_mapping.get(emotion_data['emotion'].lower(), emotion_data['emotion'])
                    logger.info(f"–ü–æ–ª—É—á–µ–Ω—ã —Ç–æ–ø-3 —ç–º–æ—Ü–∏–∏ (—Ç–µ–∫—Å—Ç): {top3_emotions}")
                else:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–ø-3 —ç–º–æ—Ü–∏–∏ –∏–∑ full_result_with_top3 (—Ç–µ–∫—Å—Ç): {full_result_with_top3}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–æ–ø-3 —ç–º–æ—Ü–∏–π (—Ç–µ–∫—Å—Ç): {e}")
                top3_emotions = []
            
            result = {
                "emotion": russian_emotion,
                "confidence": float(confidence),
                "processing_time": processing_time,
                "model": "Aniemore/Bert_Tiny2",
                "device": self.device,
                "top3_emotions": top3_emotions
            }
            
            logger.info(f"[RAW-TEXT-ANIEMORE] –°—ã—Ä–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ Aniemore: {result}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞: {e}")
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞: {e}")
    
    async def transcribe_audio(self, audio_data: bytes) -> str:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ WhisperCPP"""
        try:
            # WhisperCPP –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç base64 —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã—Ö
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
            
            transcription_request = {
                'audio_data': audio_base64,
                'language': 'ru',
                'model': 'base',
                'translate': False,
                'temperature': 0.0
            }
            
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeouts["whispercpp"])) as session:
                async with session.post(self.whispercpp_url, json=transcription_request) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result.get('text', '').strip()
                    else:
                        error_text = await response.text()
                        logger.error(f"WhisperCPP error {response.status}: {error_text}")
                        return ""
        
        except asyncio.TimeoutError:
            logger.error(f"WhisperCPP timeout after {self.timeouts['whispercpp']}s")
            return ""
        except Exception as e:
            logger.error(f"WhisperCPP error: {e}")
            return ""
    
    async def analyze_text_dostoevsky(self, text: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –≤ —Ç–µ–∫—Å—Ç–µ —á–µ—Ä–µ–∑ Dostoevsky"""
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeouts["dostoevsky"])) as session:
                data = {'text': text}
                
                async with session.post(self.dostoevsky_url, data=data) as response:
                    if response.status == 200:
                        result = await response.json()
                        logger.info(f"[RAW-TEXT-DOSTOEVSKY] –°—ã—Ä–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ Dostoevsky: {result}")
                        return result
                    else:
                        error_text = await response.text()
                        logger.error(f"Dostoevsky error {response.status}: {error_text}")
                        return {"emotion": "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è", "confidence": 0.0, "error": f"HTTP {response.status}"}
        
        except asyncio.TimeoutError:
            logger.error(f"Dostoevsky timeout after {self.timeouts['dostoevsky']}s")
            return {"emotion": "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è", "confidence": 0.0, "error": "timeout"}
        except Exception as e:
            logger.error(f"Dostoevsky error: {e}")
            return {"emotion": "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è", "confidence": 0.0, "error": str(e)}
    
    # –ú–µ—Ç–æ–¥ combine_emotion_results —É–±—Ä–∞–Ω - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —ç–º–æ—Ü–∏–π —Ç–µ–ø–µ—Ä—å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ Rust


@app.get("/emotions")
async def get_available_emotions():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —ç–º–æ—Ü–∏–π"""
    return {
        "emotions": list(ser_service.emotion_mapping.values()),
        "mapping": ser_service.emotion_mapping
    }

@app.post("/analyze")
async def analyze_voice_emotions(
    audio_file: UploadFile = File(...),
    sample_rate: int = Form(16000)
):
    """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –≤ –≥–æ–ª–æ—Å–µ"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º content_type —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç None
    if audio_file.content_type is not None and not audio_file.content_type.startswith('audio/'):
        raise HTTPException(status_code=400, detail="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∞—É–¥–∏–æ")
    
    try:
        # –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
        audio_data = await audio_file.read()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–º–æ—Ü–∏–∏
        result = await ser_service.analyze_emotions(audio_data, sample_rate)
        
        return JSONResponse(content=result)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —ç–º–æ—Ü–∏–π: {str(e)}")

@app.post("/analyze-bytes")
async def analyze_voice_emotions_bytes(
    audio_data: bytes = File(...),
    sample_rate: int = Form(16000)
):
    """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –≤ –≥–æ–ª–æ—Å–µ (–±–∞–π—Ç—ã)"""
    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–º–æ—Ü–∏–∏
        result = await ser_service.analyze_emotions(audio_data, sample_rate)
        
        return JSONResponse(content=result)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞–π—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze-bytes-json")
async def analyze_voice_emotions_bytes_json(
    request: dict
):
    """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –≤ –≥–æ–ª–æ—Å–µ (JSON —Å base64 audio_data)"""
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON –∑–∞–ø—Ä–æ—Å–∞
        audio_b64 = request.get("audio_data", "")
        sample_rate = request.get("sample_rate", 16000)
        
        if not audio_b64:
            raise HTTPException(status_code=400, detail="audio_data –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64 –≤ –±–∞–π—Ç—ã
        try:
            audio_data = base64.b64decode(audio_b64)
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è base64: {str(e)}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–º–æ—Ü–∏–∏
        result = await ser_service.analyze_emotions(audio_data, sample_rate)
        
        return JSONResponse(content=result)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSON –±–∞–π—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze-text")
async def analyze_text_emotions(
    request: dict
):
    """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π –≤ —Ç–µ–∫—Å—Ç–µ"""
    text = request.get("text", "")
    if not text.strip():
        raise HTTPException(status_code=400, detail="–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
    
    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —ç–º–æ—Ü–∏–∏ –≤ —Ç–µ–∫—Å—Ç–µ
        result = await ser_service.analyze_text_emotions(text)
        
        return JSONResponse(content=result)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞: {str(e)}")

# Endpoint /analyze-complete —É–±—Ä–∞–Ω - –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π —Ç–µ–ø–µ—Ä—å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ Rust

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    try:
        logger.info("[HEALTH] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞...")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–∞
        if ser_service.is_initialized and ser_service.text_initialized:
            service_status = "healthy"
        elif ser_service.is_initialized or ser_service.text_initialized:
            service_status = "degraded"
        else:
            service_status = "unhealthy"
        
        status = {
            "status": service_status,
            "service": "Aniemore SER Service",
            "version": "1.0.0",
            "initialized": ser_service.is_initialized,
            "text_initialized": ser_service.text_initialized,
            "device": ser_service.device,
            "voice_model": ser_service.model_name,
            "text_model": ser_service.text_model_name,
            "use_local_models": ser_service.use_local_models
        }
        
        logger.info(f"[HEALTH] –°—Ç–∞—Ç—É—Å: {status}")
        return JSONResponse(content=status)
        
    except Exception as e:
        logger.error(f"[HEALTH] –û—à–∏–±–∫–∞ health check: {e}")
        import traceback
        logger.error(f"[HEALTH] Traceback: {traceback.format_exc()}")
        return JSONResponse(
            content={
                "status": "unhealthy",
                "error": str(e),
                "service": "Aniemore SER Service"
            },
            status_code=500
        )

@app.get("/model-info")
async def get_model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    try:
        logger.info("[MODEL-INFO] –ó–∞–ø—Ä–æ—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏...")
        
        if not ser_service.is_initialized:
            return {
                "status": "not_initialized",
                "message": "–ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞",
                "device": ser_service.device,
                "voice_model": ser_service.model_name,
                "text_model": ser_service.text_model_name
            }
        
        return {
            "status": "initialized",
            "model_name": ser_service.model_name,
            "device": ser_service.device,
            "emotion_mapping": ser_service.emotion_mapping,
            "voice_model": ser_service.model_name,
            "text_model": ser_service.text_model_name,
            "model_labels": ser_service.model.config.id2label if ser_service.model and hasattr(ser_service.model, 'config') else None
        }
        
    except Exception as e:
        logger.error(f"[MODEL-INFO] –û—à–∏–±–∫–∞: {e}")
        import traceback
        logger.error(f"[MODEL-INFO] Traceback: {traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
ser_service = AniemoreSERService()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Aniemore SER Service")
    parser.add_argument("--host", default="0.0.0.0", help="Host to bind to")
    parser.add_argument("--port", type=int, default=8006, help="Port to bind to")
    parser.add_argument("--workers", type=int, default=1, help="Number of workers")
    
    args = parser.parse_args()
    
    logger.info(f"üé≠ –ó–∞–ø—É—Å–∫ Aniemore SER Service –Ω–∞ {args.host}:{args.port}")
    
    uvicorn.run(
        "aniemore_ser_service:app",
        host=args.host,
        port=args.port,
        workers=args.workers,
        reload=False
    )
